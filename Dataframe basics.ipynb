{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb89d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7789b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"app\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66b96972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"./Python-and-Spark-for-Big-Data-master/Python-and-Spark-for-Big-Data-master/Spark_DataFrames/people.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d900c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bde5607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8761b18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'name']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2739759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+\n",
      "|summary|               age|   name|\n",
      "+-------+------------------+-------+\n",
      "|  count|                 2|      3|\n",
      "|   mean|              24.5|   null|\n",
      "| stddev|7.7781745930520225|   null|\n",
      "|    min|                19|   Andy|\n",
      "|    max|                30|Michael|\n",
      "+-------+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff00ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StringType, IntegerType, StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cad104b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = [StructField(\"age\", IntegerType(), nullable = True),\n",
    "              StructField(\"name\", StringType(), nullable = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f154b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_struc = StructType(fields=data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc90ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\n",
    "    \"./Python-and-Spark-for-Big-Data-master/Python-and-Spark-for-Big-Data-master/Spark_DataFrames/people.json\", \n",
    "    schema=final_struc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b9c3de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cbd2060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0256ad7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "df[\"age\"].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc05e9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| age|\n",
      "+----+\n",
      "|null|\n",
      "|  30|\n",
      "|  19|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db1455b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pyspark.sql.column.Column, pyspark.sql.dataframe.DataFrame)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[\"age\"]), type(df.select(\"age\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f22bf0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Row(age=None, name='Michael'), pyspark.sql.types.Row)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)[0], type(df.head(2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cddceb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------+\n",
      "| age|   name|new_age|\n",
      "+----+-------+-------+\n",
      "|null|Michael|   null|\n",
      "|  30|   Andy|     60|\n",
      "|  19| Justin|     38|\n",
      "+----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"new_age\", df[\"age\"]*2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06451d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+\n",
      "| age|            Name|\n",
      "+----+----------------+\n",
      "|null|Michael_lastname|\n",
      "|  30|   Andy_lastname|\n",
      "|  19| Justin_lastname|\n",
      "+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.withColumn(\"Name\", concat(df[\"Name\"], lit(\"_lastname\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe4ee815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "| age|Name_last|\n",
      "+----+---------+\n",
      "|null|  Michael|\n",
      "|  30|     Andy|\n",
      "|  19|   Justin|\n",
      "+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"Name\", \"Name_last\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4cbd65ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"people\")\n",
    "spark.sql(\"SELECT * FROM people\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8a7bf4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"./Python-and-Spark-for-Big-Data-master/Python-and-Spark-for-Big-Data-master/Spark_DataFrames/appl_stock.csv\", \n",
    "              inferSchema=True,\n",
    "                header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7adcb9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|2010-01-04|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
      "|2010-01-05|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
      "|2010-01-06|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
      "|2010-01-08|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
      "|2010-01-11|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|\n",
      "|2010-01-12|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|\n",
      "|2010-01-13|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|\n",
      "|2010-01-14|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|\n",
      "|2010-01-15|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|\n",
      "|2010-01-19|        208.330002|215.18999900000003|        207.240004|        215.039995|182501900|27.860484999999997|\n",
      "|2010-01-20|        214.910006|        215.549994|        209.500002|            211.73|153038200|         27.431644|\n",
      "|2010-01-21|        212.079994|213.30999599999998|        207.210003|        208.069996|152038600|         26.957455|\n",
      "|2010-01-22|206.78000600000001|        207.499996|            197.16|            197.75|220441900|         25.620401|\n",
      "|2010-01-25|202.51000200000001|        204.699999|        200.190002|        203.070002|266424900|26.309658000000002|\n",
      "|2010-01-26|205.95000100000001|        213.710005|        202.580004|        205.940001|466777500|         26.681494|\n",
      "|2010-01-27|        206.849995|            210.58|        199.530001|        207.880005|430642100|26.932840000000002|\n",
      "|2010-01-28|        204.930004|        205.500004|        198.699995|        199.289995|293375600|25.819922000000002|\n",
      "|2010-01-29|        201.079996|        202.199995|        190.250002|        192.060003|311488100|         24.883208|\n",
      "|2010-02-01|192.36999699999998|             196.0|191.29999899999999|        194.729998|187469100|         25.229131|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8d5a2fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bd71cc2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES] Cannot resolve \"(Date < ((2010 - 1) - 28))\" due to data type mismatch: the left and right operands of the binary operator have incompatible types (\"DATE\" and \"INT\").; line 1 pos 0;\n'Filter (Date#652 < ((2010 - 1) - 28))\n+- Relation [Date#652,Open#653,High#654,Low#655,Close#656,Volume#657,Adj Close#658] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate < 2010-01-28\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\python\\venv\\lib\\site-packages\\pyspark\\sql\\dataframe.py:3136\u001b[0m, in \u001b[0;36mDataFrame.filter\u001b[1;34m(self, condition)\u001b[0m\n\u001b[0;32m   3080\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Filters rows using the given condition.\u001b[39;00m\n\u001b[0;32m   3081\u001b[0m \n\u001b[0;32m   3082\u001b[0m \u001b[38;5;124;03m:func:`where` is an alias for :func:`filter`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3133\u001b[0m \u001b[38;5;124;03m+---+-----+\u001b[39;00m\n\u001b[0;32m   3134\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(condition, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 3136\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3137\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(condition, Column):\n\u001b[0;32m   3138\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mfilter(condition\u001b[38;5;241m.\u001b[39m_jc)\n",
      "File \u001b[1;32m~\\python\\venv\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\python\\venv\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES] Cannot resolve \"(Date < ((2010 - 1) - 28))\" due to data type mismatch: the left and right operands of the binary operator have incompatible types (\"DATE\" and \"INT\").; line 1 pos 0;\n'Filter (Date#652 < ((2010 - 1) - 28))\n+- Relation [Date#652,Open#653,High#654,Low#655,Close#656,Volume#657,Adj Close#658] csv\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"Date < 2010-01-28\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2a91fd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|2010-01-04|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
      "|2010-01-05|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
      "|2010-01-06|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
      "|2010-01-08|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
      "|2010-01-11|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|\n",
      "|2010-01-12|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|\n",
      "|2010-01-13|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|\n",
      "|2010-01-14|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|\n",
      "|2010-01-15|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|\n",
      "|2010-01-19|        208.330002|215.18999900000003|        207.240004|        215.039995|182501900|27.860484999999997|\n",
      "|2010-01-20|        214.910006|        215.549994|        209.500002|            211.73|153038200|         27.431644|\n",
      "|2010-01-21|        212.079994|213.30999599999998|        207.210003|        208.069996|152038600|         26.957455|\n",
      "|2010-01-22|206.78000600000001|        207.499996|            197.16|            197.75|220441900|         25.620401|\n",
      "|2010-01-25|202.51000200000001|        204.699999|        200.190002|        203.070002|266424900|26.309658000000002|\n",
      "|2010-01-26|205.95000100000001|        213.710005|        202.580004|        205.940001|466777500|         26.681494|\n",
      "|2010-01-27|        206.849995|            210.58|        199.530001|        207.880005|430642100|26.932840000000002|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"Date\"] < \"2010-01-28\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ea50b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      Date|     Close|\n",
      "+----------+----------+\n",
      "|2010-01-04|214.009998|\n",
      "|2010-01-05|214.379993|\n",
      "+----------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"Close < 500\").select([\"Date\", \"Close\"]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "62fd056c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      Date|     Close|\n",
      "+----------+----------+\n",
      "|2010-01-04|214.009998|\n",
      "|2010-01-05|214.379993|\n",
      "+----------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"Close\"] < 500).select([\"Date\", \"Close\"]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ee002e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|      Date|             Close|\n",
      "+----------+------------------+\n",
      "|2012-02-15|        497.669975|\n",
      "|2013-08-14|        498.500008|\n",
      "|2013-08-15|497.90998099999996|\n",
      "|2013-09-04|        498.690025|\n",
      "|2013-09-05|495.26997400000005|\n",
      "|2013-09-06|498.22000099999997|\n",
      "|2013-10-14|        496.039978|\n",
      "|2013-10-15|        498.679985|\n",
      "|2014-01-30|        499.779984|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df[\"Close\"] < 500) & (df[\"Close\"]>495)).select([\"Date\", \"Close\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "00b12f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': datetime.date(2010, 1, 4),\n",
       " 'Open': 213.429998,\n",
       " 'High': 214.499996,\n",
       " 'Low': 212.38000099999996,\n",
       " 'Close': 214.009998,\n",
       " 'Volume': 123432400,\n",
       " 'Adj Close': 27.727039}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)[0].asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3d0c45cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"./Python-and-Spark-for-Big-Data-master/Python-and-Spark-for-Big-Data-master/Spark_DataFrames/sales_info.csv\", \n",
    "                   inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e3e0d25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Person: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "66dea63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "+-------+-------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "116d0472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Company|count|\n",
      "+-------+-----+\n",
      "|   APPL|    4|\n",
      "|   GOOG|    3|\n",
      "|     FB|    2|\n",
      "|   MSFT|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "22d53f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Company|sum(Sales)|\n",
      "+-------+----------+\n",
      "|   APPL|    1480.0|\n",
      "|   GOOG|     660.0|\n",
      "|     FB|    1220.0|\n",
      "|   MSFT|     967.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\").sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "221cc768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Company|max(Sales)|\n",
      "+-------+----------+\n",
      "|   APPL|     750.0|\n",
      "|   GOOG|     340.0|\n",
      "|     FB|     870.0|\n",
      "|   MSFT|     600.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\").max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d2006ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(Sales)|\n",
      "+----------+\n",
      "|    4327.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({\"Sales\": \"sum\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "623440ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|count(Sales)|\n",
      "+------------+\n",
      "|          12|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({\"Sales\": \"count\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "57e24db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Company|sum(Sales)|\n",
      "+-------+----------+\n",
      "|   APPL|    1480.0|\n",
      "|   GOOG|     660.0|\n",
      "|     FB|    1220.0|\n",
      "|   MSFT|     967.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\").agg({\"Sales\": \"sum\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "930c1d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Company|\n",
      "+-------+\n",
      "|   APPL|\n",
      "|   GOOG|\n",
      "|     FB|\n",
      "|   MSFT|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Company\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a881a46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|        Avg_sales|\n",
      "+-----------------+\n",
      "|360.5833333333333|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(pyspark.sql.functions.avg(\"Sales\").alias(\"Avg_sales\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f154d9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|Avg_sales|\n",
      "+---------+\n",
      "|   360.58|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(pyspark.sql.functions.format_number(pyspark.sql.functions.avg(\"Sales\"), 2).alias(\"Avg_sales\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "56bc5c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|     FB|   Carl|870.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "08a329e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+\n",
      "|Company| Person|sum(Sales)|\n",
      "+-------+-------+----------+\n",
      "|   GOOG|    Sam|     200.0|\n",
      "|     FB|  Sarah|     350.0|\n",
      "|   APPL|  Chris|     350.0|\n",
      "|   MSFT|Vanessa|     243.0|\n",
      "|   APPL|   John|     250.0|\n",
      "|   APPL|  Linda|     130.0|\n",
      "|   GOOG|Charlie|     120.0|\n",
      "|   APPL|   Mike|     750.0|\n",
      "|     FB|   Carl|     870.0|\n",
      "|   MSFT|   Tina|     600.0|\n",
      "|   MSFT|    Amy|     124.0|\n",
      "|   GOOG|  Frank|     340.0|\n",
      "+-------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy([\"Company\", \"Person\"]).sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "29c2c106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+\n",
      "|Company| Person|sum(Sales)|\n",
      "+-------+-------+----------+\n",
      "|   GOOG|    Sam|     200.0|\n",
      "|     FB|  Sarah|     350.0|\n",
      "|   APPL|  Chris|     350.0|\n",
      "|   MSFT|Vanessa|     243.0|\n",
      "|   APPL|   John|     250.0|\n",
      "|   APPL|  Linda|     130.0|\n",
      "|   GOOG|Charlie|     120.0|\n",
      "|   APPL|   Mike|     750.0|\n",
      "|     FB|   Carl|     870.0|\n",
      "|   MSFT|   Tina|     600.0|\n",
      "|   MSFT|    Amy|     124.0|\n",
      "|   GOOG|  Frank|     340.0|\n",
      "+-------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy([\"Company\", \"Person\"]).sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ba68b7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|     FB|   Carl|870.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"Sales\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "131c858f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|     FB|   Carl|870.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"Sales\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e136255e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|     FB|   Carl|870.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df[\"Sales\"].desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5858e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"./Python-and-Spark-for-Big-Data-master/Python-and-Spark-for-Big-Data-master/Spark_DataFrames/ContainsNull.csv\",\n",
    "                   inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4f30f9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+\n",
      "|  Id|Name|Sales|\n",
      "+----+----+-----+\n",
      "|emp1|John| null|\n",
      "|emp2|null| null|\n",
      "+----+----+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f36fdf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "df35ad79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a65ebcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|sum(null)|\n",
      "+---------+\n",
      "|        2|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df[\"Name\"].isNull().cast(\"integer\").alias(\"null\")).agg({\"null\": \"sum\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "744d3142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|sum(CAST((Name IS NULL) AS INT))|\n",
      "+--------------------------------+\n",
      "|                               2|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(pyspark.sql.functions.sum(df[\"Name\"].isNull().cast(\"integer\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bd5bb48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|sum(CAST((Name IS NULL) AS INT))|\n",
      "+--------------------------------+\n",
      "|                               2|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(pyspark.sql.functions.sum(df[\"Name\"].isNull().cast(\"integer\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "847c968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp2| null| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e7b0287e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c5852d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp2| null| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how=\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "5f683a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(thresh=2).show() # thresh count not null < threshold values in ROW\n",
    "# We can see all rows have atleast 2 not null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c78c4d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(subset=\"Sales\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d2f648e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-----+\n",
      "|  Id|  Name|Sales|\n",
      "+----+------+-----+\n",
      "|emp1|  John| null|\n",
      "|emp2|Filled| null|\n",
      "|emp3|Filled|345.0|\n",
      "|emp4| Cindy|456.0|\n",
      "+----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(\"Filled\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "16421451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| 10.0|\n",
      "|emp2| null| 10.0|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "49e437c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(avg(Sales)=400.5)]\n",
      "400.5\n"
     ]
    }
   ],
   "source": [
    "mean = df.select(pyspark.sql.functions.mean(df[\"Sales\"])).collect()\n",
    "print(mean)\n",
    "mean_value = mean[0][0]\n",
    "print(mean_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "8d61adb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|400.5|\n",
      "|emp2| null|400.5|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(mean_value, subset=\"Sales\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "31b75d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400.5"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"sales\").agg({\"sales\": \"mean\"}).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "bcb19b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"./Python-and-Spark-for-Big-Data-master/Python-and-Spark-for-Big-Data-master/Spark_DataFrames/appl_stock.csv\", \n",
    "                   inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "12072d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|2010-01-04|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
      "|2010-01-05|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
      "|2010-01-06|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
      "|2010-01-08|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
      "|2010-01-11|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|\n",
      "|2010-01-12|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|\n",
      "|2010-01-13|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|\n",
      "|2010-01-14|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|\n",
      "|2010-01-15|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|\n",
      "|2010-01-19|        208.330002|215.18999900000003|        207.240004|        215.039995|182501900|27.860484999999997|\n",
      "|2010-01-20|        214.910006|        215.549994|        209.500002|            211.73|153038200|         27.431644|\n",
      "|2010-01-21|        212.079994|213.30999599999998|        207.210003|        208.069996|152038600|         26.957455|\n",
      "|2010-01-22|206.78000600000001|        207.499996|            197.16|            197.75|220441900|         25.620401|\n",
      "|2010-01-25|202.51000200000001|        204.699999|        200.190002|        203.070002|266424900|26.309658000000002|\n",
      "|2010-01-26|205.95000100000001|        213.710005|        202.580004|        205.940001|466777500|         26.681494|\n",
      "|2010-01-27|        206.849995|            210.58|        199.530001|        207.880005|430642100|26.932840000000002|\n",
      "|2010-01-28|        204.930004|        205.500004|        198.699995|        199.289995|293375600|25.819922000000002|\n",
      "|2010-01-29|        201.079996|        202.199995|        190.250002|        192.060003|311488100|         24.883208|\n",
      "|2010-02-01|192.36999699999998|             196.0|191.29999899999999|        194.729998|187469100|         25.229131|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "6e6a552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select([\"Date\", \"Volume\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "f2436242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|      Date|  Volume|\n",
      "+----------+--------+\n",
      "|2016-12-30|30586300|\n",
      "|2016-12-29|15039500|\n",
      "+----------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df[\"Date\"].desc()).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "841322af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import dayofmonth, hour, dayofyear, month, year, weekofyear, date_format, format_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "0511c360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+\n",
      "|      Date|dayofmonth(Date)|\n",
      "+----------+----------------+\n",
      "|2010-01-04|               4|\n",
      "|2010-01-05|               5|\n",
      "+----------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([\"Date\", dayofmonth(df[\"Date\"])]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "dedeab49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|      Date|month(Date)|\n",
      "+----------+-----------+\n",
      "|2010-01-04|          1|\n",
      "|2010-01-05|          1|\n",
      "+----------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([\"Date\", month(df[\"Date\"])]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "ca2908ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      Date|year(Date)|\n",
      "+----------+----------+\n",
      "|2010-01-04|      2010|\n",
      "|2010-01-05|      2010|\n",
      "+----------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([\"Date\", year(df[\"Date\"])]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "cc9f7ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|2010|  252|\n",
      "|2011|  252|\n",
      "|2012|  250|\n",
      "|2013|  252|\n",
      "|2014|  252|\n",
      "|2015|  252|\n",
      "|2016|  252|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([year(df[\"Date\"]).alias(\"year\")]).groupby(\"year\").count().orderBy(\"year\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "218a9157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|year|         avg(Volume)|\n",
      "+----+--------------------+\n",
      "|2010|1.4982631666666666E8|\n",
      "|2011|1.2307474166666667E8|\n",
      "|2012|       1.319642044E8|\n",
      "|2013|          1.016087E8|\n",
      "|2014| 6.315273055555555E7|\n",
      "|2015|  5.18378869047619E7|\n",
      "|2016|  3.84153623015873E7|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_vol_per_year = df.select([year(df[\"Date\"]).alias(\"year\"), \"Volume\"]).groupby(\"year\").agg({\"Volume\":\"avg\"}).orderBy(\"year\")\n",
    "avg_vol_per_year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "7fd0e88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------+\n",
      "|year|format_number(avg(Volume), 2)|\n",
      "+----+-----------------------------+\n",
      "|2010|               149,826,316.67|\n",
      "|2011|               123,074,741.67|\n",
      "|2012|               131,964,204.40|\n",
      "|2013|               101,608,700.00|\n",
      "|2014|                63,152,730.56|\n",
      "|2015|                51,837,886.90|\n",
      "|2016|                38,415,362.30|\n",
      "+----+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_vol_per_year.select([\"year\", format_number(\"avg(Volume)\", 2)]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2241078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
